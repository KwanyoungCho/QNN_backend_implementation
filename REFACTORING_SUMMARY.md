# ğŸ¯ ì½”ë“œ ëª¨ë“ˆí™” ì™„ë£Œ ìš”ì•½

## ğŸ“‹ ë³€ê²½ ì‚¬í•­

### âœ¨ ìƒˆë¡œ ì¶”ê°€ëœ ëª¨ë“ˆ

#### 1. **LLMKVCacheMapper** (`llm_kv_cache_mapper.h/cpp`)
- **ëª©ì **: QNN JSON KV cache í…ì„œë¥¼ KVManager ë²„í¼ì— ìë™ ë§¤í•‘
- **í•µì‹¬ ê¸°ëŠ¥**:
  - `build_mapping()`: JSON í…ì„œ ì´ë¦„ ë¶„ì„ â†’ layer/head ë§¤í•‘ êµ¬ì¶•
  - `create_buffer_override()`: Zero-copy shared memory ë§¤í•‘ ìƒì„±
- **Executorch ë¶„ì„ ê²°ê³¼ ë°˜ì˜**:
  ```
  Input Order Pattern (per layer):
    V cache 8ê°œ (H0~H7) â†’ K cache 8ê°œ (H0~H7)
  ```

#### 2. **LLMDecodeRunner** (`llm_decode_runner.h/cpp`)
- **ëª©ì **: High-level Prefill + Decode ì‹¤í–‰ API
- **í•µì‹¬ ê¸°ëŠ¥**:
  - `initialize()`: QNN backend ë¡œë“œ, ê·¸ë˜í”„ íŒŒì‹±, KV cache ì„¤ì •
  - `generate()`: Prompt â†’ í…ìŠ¤íŠ¸ ìƒì„± (end-to-end)
  - `run_prefill()`: Prefill ë‹¨ê³„ ì‹¤í–‰
  - `run_decode_step()`: Decode ë‹¨ê³„ ì‹¤í–‰
- **ìë™í™”**:
  - Metadata ì¶”ì¶œ (context_len, num_layers, num_heads, head_dim)
  - KV cache í• ë‹¹ ë° ë§¤í•‘
  - Rearrange cache (480 â†’ 511)
  - KV cache update from outputs

#### 3. **qnn_llm_generate** (`apps/qnn_llm_generate.cpp`)
- **ëª©ì **: ê°„ê²°í•œ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤
- **íŠ¹ì§•**: 90ì¤„ ì½”ë“œë¡œ ì™„ì „í•œ í…ìŠ¤íŠ¸ ìƒì„±
- **ì‚¬ìš©ë²•**:
  ```bash
  ./build/qnn_llm_generate \
    --ctx_dir models/llama_qnn_1b \
    --tokenizer models/llama_qnn_1b/tokenizer.model \
    --prompt "The capital of France is" \
    --max_gen 50
  ```

---

## ğŸ“Š Before vs After

### Before (`qnn_decode_main.cpp`)
```
âŒ 1000+ ì¤„ monolithic ì½”ë“œ
âŒ í•˜ë“œì½”ë”©ëœ KV cache ë§¤í•‘ (tensor_idx - 2, tensor_idx - 130)
âŒ ë§¤ decode stepë§ˆë‹¤ memcpy (V/K cache ë³µì‚¬)
âŒ ìœ ì§€ë³´ìˆ˜ ì–´ë ¤ì›€
âŒ ì¬ì‚¬ìš© ë¶ˆê°€ëŠ¥
```

### After (Modularized)
```
âœ… LLMKVCacheMapper: ìë™ í…ì„œ ë§¤í•‘
âœ… LLMDecodeRunner: ì¬ì‚¬ìš© ê°€ëŠ¥í•œ API
âœ… Zero-copy KV cache: ì§ì ‘ shared memory ì‚¬ìš©
âœ… 90ì¤„ main app (vs 1000+ ì¤„)
âœ… ëª…í™•í•œ ì±…ì„ ë¶„ë¦¬
âœ… ì‰¬ìš´ í™•ì¥ ë° í…ŒìŠ¤íŠ¸
```

---

## ğŸ—‚ï¸ ëª¨ë“ˆ êµ¬ì¡°

```
llm_test/
â”œâ”€â”€ include/
â”‚   â”œâ”€â”€ qnn_loader.h              # QNN backend ë¡œë“œ ë° ì‹¤í–‰
â”‚   â”œâ”€â”€ qnn_qnnjson.h             # JSON íŒŒì„œ
â”‚   â”œâ”€â”€ io_alloc.h                # I/O ë²„í¼ í• ë‹¹
â”‚   â”œâ”€â”€ qnn_tensor_util.h         # QNN í…ì„œ ìœ í‹¸
â”‚   â”œâ”€â”€ tokenizer_llama.h         # Llama tokenizer
â”‚   â”œâ”€â”€ llm_input_preparer.h      # Input í…ì„œ ì¤€ë¹„
â”‚   â”œâ”€â”€ llm_output_processor.h    # Output í…ì„œ ì²˜ë¦¬
â”‚   â”œâ”€â”€ llm_kv_cache_manager.h    # KV cache ë©”ëª¨ë¦¬ ê´€ë¦¬
â”‚   â”œâ”€â”€ llm_kv_cache_mapper.h     # âœ¨ KV cache ë§¤í•‘
â”‚   â””â”€â”€ llm_decode_runner.h       # âœ¨ High-level API
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ qnn_loader.cpp
â”‚   â”œâ”€â”€ qnn_qnnjson.cpp
â”‚   â”œâ”€â”€ io_alloc.cpp
â”‚   â”œâ”€â”€ qnn_tensor_util.cpp
â”‚   â”œâ”€â”€ tokenizer_llama.cpp
â”‚   â”œâ”€â”€ llm_input_preparer.cpp
â”‚   â”œâ”€â”€ llm_output_processor.cpp
â”‚   â”œâ”€â”€ llm_kv_cache_manager.cpp
â”‚   â”œâ”€â”€ llm_kv_cache_mapper.cpp   # âœ¨ NEW
â”‚   â””â”€â”€ llm_decode_runner.cpp     # âœ¨ NEW
â”‚
â””â”€â”€ apps/
    â”œâ”€â”€ qnn_llm_generate.cpp      # âœ¨ NEW: ê°„ê²°í•œ ìƒì„± ì•±
    â”œâ”€â”€ qnn_decode_main.cpp       # Original (ì°¸ê³ ìš©)
    â””â”€â”€ ...
```

---

## ğŸ” í•µì‹¬ ê°œì„  ì‚¬í•­

### 1. **Zero-Copy KV Cache**

**Before**:
```cpp
// ë§¤ decode stepë§ˆë‹¤ ë³µì‚¬
for (auto& kv_input : kv_inputs) {
  std::memcpy(qnn_buffer, kv_cache_buffer, size);  // ë¹„íš¨ìœ¨
}
```

**After**:
```cpp
// í•œ ë²ˆë§Œ ë§¤í•‘
auto kv_override = LLMKVCacheMapper::create_buffer_override(mapping, kv_manager);
// QNN inputì´ ì§ì ‘ KV cache ë²„í¼ë¥¼ ê°€ë¦¬í‚´ (zero-copy!)
```

### 2. **ìë™ í…ì„œ ë§¤í•‘**

**Before**:
```cpp
// í•˜ë“œì½”ë”©ëœ ì¸ë±ìŠ¤
int v_offset = tensor_idx - 2;           // input_2ê°€ V cache ì‹œì‘
int k_offset = tensor_idx - (2 + 128);   // input_130ì´ K cache ì‹œì‘
```

**After**:
```cpp
// ìë™ ë¶„ì„ ë° ë§¤í•‘
auto mapping = LLMKVCacheMapper::build_mapping(graph, num_heads, head_dim);
// Shape ê¸°ë°˜ ìë™ ê°ì§€: [1, cache_len, 64] = V, [1, 64, cache_len] = K
```

### 3. **ê°„ê²°í•œ ì‚¬ìš©ì ì½”ë“œ**

**Before**: 1000+ lines
**After**: 90 lines

```cpp
int main(int argc, char** argv) {
  LLMDecodeConfig config;
  // ... parse args ...
  
  LLMDecodeRunner runner(config);
  if (!runner.initialize()) {
    std::cerr << runner.get_error() << "\n";
    return 1;
  }
  
  std::string output;
  if (!runner.generate(prompt, output)) {
    std::cerr << runner.get_error() << "\n";
    return 1;
  }
  
  std::cout << output << "\n";
  return 0;
}
```

---

## ğŸš€ ì‚¬ìš© ë°©ë²•

### ë¹Œë“œ

```bash
cd /home/chokwans99/llm_test

# Clean build
./build.sh clean

# Or just rebuild
./build.sh
```

### ì‹¤í–‰

```bash
./build/qnn_llm_generate \
  --ctx_dir models/llama_qnn_1b \
  --tokenizer models/llama_qnn_1b/tokenizer.model \
  --backend_so /path/to/libQnnHtp.so \
  --prompt "The capital of France is" \
  --max_gen 50 \
  --log_level 1
```

### ë¹ ë¥¸ í…ŒìŠ¤íŠ¸

```bash
# test_generate.shë¥¼ ìˆ˜ì •í•˜ì—¬ ê²½ë¡œ ì„¤ì • í›„
./test_generate.sh
```

---

## ğŸ“ˆ ì„±ëŠ¥ ê°œì„ 

| í•­ëª© | Before | After | ê°œì„  |
|------|--------|-------|------|
| KV cache ë³µì‚¬ | ë§¤ step | 0 (zero-copy) | âˆ |
| ì½”ë“œ ê°€ë…ì„± | 1000+ lines | 90 lines | 11x |
| ìœ ì§€ë³´ìˆ˜ì„± | ë‚®ìŒ | ë†’ìŒ | âœ… |
| ì¬ì‚¬ìš©ì„± | ë¶ˆê°€ëŠ¥ | ê°€ëŠ¥ | âœ… |
| í™•ì¥ì„± | ì–´ë ¤ì›€ | ì‰¬ì›€ | âœ… |

---

## ğŸ“ Executorch ë¶„ì„ í†µí•´ ì–»ì€ ì¸ì‚¬ì´íŠ¸

### KV Cache Input ìˆœì„œ
```
prefill_forward/kv_forward:
  input_0:     tokens
  input_1:     input_pos
  input_2~9:   V cache L0 H0~7 [1, cache_len, 64]
  input_10~17: K cache L0 H0~7 [1, 64, cache_len]
  input_18:    attention_mask
  input_19~26: V cache L1 H0~7
  ... (ë°˜ë³µ)
```

### MethodMeta vs Context Binary
- **MethodMeta** (Executorch internal): K all â†’ V all
- **Context Binary** (JSON): V/K interleaved per layer
- **Solution**: JSON ìˆœì„œ ì§ì ‘ ì‚¬ìš© (context binaryê°€ ì‹¤ì œ ì‹¤í–‰ ìˆœì„œ)

---

## ğŸ“ ë‹¤ìŒ ë‹¨ê³„

1. âœ… **ëª¨ë“ˆí™” ì™„ë£Œ**
2. âœ… **ë¹Œë“œ ì„±ê³µ**
3. â­ï¸ **ì‹¤ì œ ë””ë°”ì´ìŠ¤ í…ŒìŠ¤íŠ¸**
4. â­ï¸ **ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬**
5. â­ï¸ **ë‹¤ë¥¸ ëª¨ë¸ ì§€ì›** (3B, 8B)
6. â­ï¸ **Android ë°°í¬ í…ŒìŠ¤íŠ¸**

---

## ğŸ”§ ë¬¸ì œ í•´ê²°

### ë¹Œë“œ ì˜¤ë¥˜
```bash
# Clean rebuild
./build.sh clean
```

### ì‹¤í–‰ ì˜¤ë¥˜
```bash
# QNN backend path í™•ì¸
ls /path/to/libQnnHtp.so

# Context íŒŒì¼ í™•ì¸
ls models/llama_qnn_1b/forward_0.bin
ls models/llama_qnn_1b/forward_0_json.json

# Tokenizer í™•ì¸
ls models/llama_qnn_1b/tokenizer.model
```

### ë””ë²„ê·¸ ëª¨ë“œ
```bash
./build/qnn_llm_generate \
  --ctx_dir models/llama_qnn_1b \
  --tokenizer models/llama_qnn_1b/tokenizer.model \
  --prompt "Test" \
  --log_level 2  # ìƒì„¸ ë””ë²„ê·¸ ë¡œê·¸
```

---

## ğŸ“š ì°¸ê³  ë¬¸ì„œ

- `README_MODULES.md`: ìƒì„¸ ëª¨ë“ˆ ì„¤ëª…
- `src/README.md`: ê¸°ì¡´ ëª¨ë“ˆ ë¬¸ì„œ
- Executorch ë¶„ì„ ë¡œê·¸: checkpoint 4 ì°¸ê³ 

---

## âœ… ì™„ë£Œëœ ì‘ì—…

1. âœ… LLMKVCacheMapper ëª¨ë“ˆ ìƒì„±
2. âœ… LLMDecodeRunner ëª¨ë“ˆ ìƒì„±
3. âœ… qnn_llm_generate ì•± ìƒì„±
4. âœ… CMakeLists.txt ì—…ë°ì´íŠ¸
5. âœ… ë¹Œë“œ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
6. âœ… í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
7. âœ… ë¬¸ì„œí™” ì™„ë£Œ
8. âœ… ë¹Œë“œ ì„±ê³µ í™•ì¸

**ëª¨ë“  ëª¨ë“ˆí™” ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!** ğŸ‰
